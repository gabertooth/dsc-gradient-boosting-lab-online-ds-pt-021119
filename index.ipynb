{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn how to use both Adaboost and Gradient Boosting Classifiers from scikit-learn!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Compare and contrast Adaboost and Gradient Boosting\n",
    "* Use adaboost to make predictions on a dataset\n",
    "* Use Gradient Boosting to make predictions on a dataset\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we'll learn how to use Boosting algorithms to make classifications on the [Pima Indians Dataset](http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names). You will find the data stored within the file `pima-indians-diabetes.csv`. Our goal is to use boosting algorithms to classify each person as having or not having diabetes. Let's get started!\n",
    "\n",
    "We'll begin by importing everything we need for this lab. In the cell below:\n",
    "\n",
    "* Import `numpy`, `pandas`, and `matplotlib.pyplot`, and set the standard alias for each. Also set matplotlib visualizations to display inline. \n",
    "* Set a random seed of `0` by using `np.random.seed(0)`\n",
    "* Import `train_test_split` and `cross_val_score` from `sklearn.model_selection`\n",
    "* Import `StandardScaler` from `sklearn.preprocessing`\n",
    "* Import `AdaboostClassifier` and `GradientBoostingClassifier` from `sklearn.ensemble`\n",
    "* Import `accuracy_score`, `f1_score`, `confusion_matrix`, and `classification_report` from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use pandas to read in the data stored in `pima-indians-diabetes.csv` and store it in a DataFrame. Display the head to inspect the data we've imported and ensure everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, Exploration, and Preprocessing\n",
    "\n",
    "The target we're trying to predict is the `'Outcome'` column. A `1` denotes a patient with diabetes. \n",
    "\n",
    "By now, you're quite familiar with exploring and preprocessing a dataset, so we won't hold your hand for this step. \n",
    "\n",
    "In the following cells:\n",
    "\n",
    "* Store our target column in a separate variable and remove it from the dataset\n",
    "* Check for null values and deal with them as you see fit (if any exist)\n",
    "* Check the distribution of our target\n",
    "* Scale the dataset\n",
    "* Split the dataset into training and testing sets, with a `test_size` of `0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Outcome']]\n",
    "df.drop('Outcome', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a18bc65f8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 8 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 48.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age  \n",
       "count  768.000000                768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885  \n",
       "std      7.884160                  0.331329   11.760232  \n",
       "min      0.000000                  0.078000   21.000000  \n",
       "25%     27.300000                  0.243750   24.000000  \n",
       "50%     32.000000                  0.372500   29.000000  \n",
       "75%     36.600000                  0.626250   41.000000  \n",
       "max     67.100000                  2.420000   81.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.639947  0.848324       0.149641       0.907270 -0.692891  0.204013   \n",
       "1    -0.844885 -1.123396      -0.160546       0.530902 -0.692891 -0.684422   \n",
       "2     1.233880  1.943724      -0.263941      -1.288212 -0.692891 -1.103255   \n",
       "3    -0.844885 -0.998208      -0.160546       0.154533  0.123302 -0.494043   \n",
       "4    -1.141852  0.504055      -1.504687       0.907270  0.765836  1.409746   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  \n",
       "0                  0.468492  1.425995  \n",
       "1                 -0.365061 -0.190672  \n",
       "2                  0.604397 -0.105584  \n",
       "3                 -0.920763 -1.041549  \n",
       "4                  5.484909 -0.020496  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_df, target, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Models\n",
    "\n",
    "Now that we've cleaned and preprocessed our dataset, we're ready to fit some models!\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create an `AdaBoostClassifier`\n",
    "* Create a `GradientBoostingClassifer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "gbt_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train each of the classifiers using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf.fit(X_train,y_train)\n",
    "gbt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create some predictions using each model so that we can calculate the training and testing accuracy for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_train_preds = adaboost_clf.predict(X_train)\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test)\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete the following function and use it to calculate the training and testing accuracy and f1-score for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.8229166666666666\n",
      "F1-Score: 0.7424242424242425\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.9322916666666666\n",
      "F1-Score: 0.9007633587786259\n",
      "\n",
      "Testing Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.7864583333333334\n",
      "F1-Score: 0.6554621848739496\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.8125\n",
      "F1-Score: 0.6727272727272728\n"
     ]
    }
   ],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go one step further and create a confusion matrix and classification report for each. Do so in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  18],\n",
       "       [ 23,  39]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test, adaboost_test_preds)\n",
    "adaboost_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,  11],\n",
       "       [ 25,  37]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "gbt_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       130\n",
      "           1       0.68      0.63      0.66        62\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       192\n",
      "   macro avg       0.76      0.75      0.75       192\n",
      "weighted avg       0.78      0.79      0.78       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_classification_report = classification_report(y_test, adaboost_test_preds)\n",
    "print(adaboost_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       130\n",
      "           1       0.77      0.60      0.67        62\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       192\n",
      "   macro avg       0.80      0.76      0.77       192\n",
      "weighted avg       0.81      0.81      0.81       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_classification_report = classification_report(y_test, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** How did the models perform? Interpret the evaluation metrics above to answer this question.\n",
    "\n",
    "Write your answer below this line:\n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    " \n",
    " \n",
    "As a final performance check, let's calculate the `cross_val_score` for each model! Do so now in the cells below. \n",
    "\n",
    "Recall that to compute the cross validation score, we need to pass in:\n",
    "\n",
    "* a classifier\n",
    "* All training Data\n",
    "* All labels\n",
    "* The number of folds we want in our cross validation score. \n",
    "\n",
    "Since we're computing cross validation score, we'll want to pass in the entire (scaled) dataset, as well as all of the labels. We don't need to give it data that has been split into training and testing sets because it will handle this step during the cross validation. \n",
    "\n",
    "In the cells below, compute the mean cross validation score for each model. For the data, use our `scaled_df` variable. The corresponding labels are in the variable `target`. Also set `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Adaboost Cross-Val Score (k=5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7631270690094218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print('Mean Adaboost Cross-Val Score (k=5):')\n",
    "print(cross_val_score(adaboost_clf, scaled_df, target, cv=5).mean())\n",
    "# Expected Output: 0.7631270690094218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean GBT Cross-Val Score (k=5):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591715474068416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/gabrielblatstein/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print('Mean GBT Cross-Val Score (k=5):')\n",
    "print(cross_val_score(gbt_clf, scaled_df, target, cv=5).mean())\n",
    "# Expected Output: 0.7591715474068416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models didn't do poorly, but we could probably do a bit better by tuning some of the important parameters such as the **_Learning Rate_**. \n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we learned how to use scikit-learn's implementations of popular boosting algorithms such as AdaBoost and Gradient Boosted Trees to make classification predictions on a real-world dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
